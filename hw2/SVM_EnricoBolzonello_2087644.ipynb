{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for classification, without and with kernels\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVMs) for image classification. We are going to use the famous MNIST dataset, that is a dataset of handwritten digits. We get the data from mldata.org, that is a public repository for machine learning data.\n",
    "\n",
    "The dataset consists of 70,000 images of handwritten digits (i.e., 0, 1, ... 9). Each image is 28 pixels by 28 pixels and we can think of it as a vector of 28x28 = 784 numbers. Each number is an integer between 0 and 255. For each image we have the corresponding label (i.e., 0, 1, ..., 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from tabulate import tabulate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator\n",
    "ID = 2087644\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the dataset. 'data' contains the input, 'target' contains the label. We normalize the data by dividing each value by 255 so that each value is in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the MNIST dataset and let's normalize the features so that each value is in [0,1]\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# rescale the data\n",
    "X, y = mnist.data.values / 255., mnist.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. We keep 500 samples in the training set. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens.\n",
    "\n",
    "**IMPORTANT**: if you cannot run the SVM with 500 samples or 1000 samples (see below), try with a smaller number of samples (e.g. 200 here and 400 below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and frequencies in training dataset: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object),\n",
       " array([45, 72, 52, 38, 37, 45, 58, 46, 62, 45]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 500\n",
    "#data samples as training and the rests as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 500\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "print(\"Labels and frequencies in training dataset: \")\n",
    "np.unique(y_train, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now provide a function to print an image in the dataset and the corresponding true label given the index of the image in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a digit and printing the corresponding labe\n",
    "def plot_digit(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %s\" % labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's print the 100-th image in X_train and the 40,000-th image in X_test and their true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOLklEQVR4nO3df4xV9ZnH8c8jAglQCcjoTixZavUPzEYpTkgNhqjNNgIm2Gg3xVgxmqXxV1rDHxo2sUKiMevWBuNKMhUCJV0qhhqJISxI6g8SbBwMi7iTFdZMKXWEixorRoXBp3/MsZninO8d7jn3nss871cyufee55x7Hm7mw7lzvufer7m7AIx+51TdAIDWIOxAEIQdCIKwA0EQdiCIc1u5s2nTpvmMGTNauUsglL6+Ph07dsyGqxUKu5ldL2mVpDGSnnH3x1Lrz5gxQz09PUV2CSChq6srt9bw23gzGyPpPyXNl3SZpMVmdlmjzweguYr8zT5H0kF3f9fdT0j6raRF5bQFoGxFwn6RpD8NeXw4W/Z3zGypmfWYWU+tViuwOwBFFAn7cCcBvnbtrbt3u3uXu3d1dHQU2B2AIoqE/bCk6UMef1PSe8XaAdAsRcL+hqRLzexbZjZO0o8kbSmnLQBla3jozd0HzOxeSf+twaG3te7+dmmdAShVoXF2d98qaWtJvQBoIi6XBYIg7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRRaMpmM+uT9ImkU5IG3L2rjKYAlK9Q2DPXuvuxEp4HQBPxNh4IomjYXdJ2M9tjZkuHW8HMlppZj5n11Gq1grsD0KiiYZ/r7rMlzZd0j5nNO30Fd+929y537+ro6Ci4OwCNKhR2d38vuz0q6XlJc8poCkD5Gg67mU00s298dV/S9yXtL6sxAOUqcjb+QknPm9lXz/Nf7r6tlK4QwmeffZasDwwMNG3fEydOTNbPOWf0nbtuOOzu/q6kK0rsBUATjb7/vgAMi7ADQRB2IAjCDgRB2IEgyvggDEax/v7+ZH3Hjh3J+p49e3Jr27alR2oPHjyYrBfx1FNPJet33XVX0/ZdFY7sQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+yjQF9fX25t9+7dyW3rjZOvW7cuWc8+4nzWWbVqVbJ+yy23JOuTJ08us52W4MgOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzt4Cx48fT9brfa77ueeea3j7evtutvHjx+fWZs6c2dR9v/POO7m1AwcOJLf9/PPPk3XG2QG0LcIOBEHYgSAIOxAEYQeCIOxAEIQdCIJx9hL09vYm64888kiyvnHjxjLbOSNz585N1q+99tpk/aqrrkrWJ0yYkFubN29ectuiZs+enVt7//33k9uOHTu27HYqV/fIbmZrzeyome0fsmyqme0wswPZ7ZTmtgmgqJG8jV8n6frTlj0oaae7XyppZ/YYQBurG3Z3f1XSh6ctXiRpfXZ/vaQby20LQNkaPUF3obv3S1J2e0Heima21Mx6zKynVqs1uDsARTX9bLy7d7t7l7t3dXR0NHt3AHI0GvYjZtYpSdnt0fJaAtAMjYZ9i6Ql2f0lkl4opx0AzVJ3nN3MNkq6RtI0Mzss6eeSHpO0yczulHRI0g+b2WQ72LdvX27tvvvuS267a9euQvvu7OxM1m+77bbc2oIFC5Lb1hsnHzNmTLJ+tlq4cGGyvnfv3mS93jUC557bfpew1O3I3RfnlL5Xci8AmojLZYEgCDsQBGEHgiDsQBCEHQii/cYHKvLaa68l6zfddFNu7YMPPkhuW+/KwXofI73//vuT9Tlz5iTrUd1xxx25tZUrVya33bBhQ8PPLUlPP/10sl4FjuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EESYcfbdu3cn64sWLUrWP/7449za+eefn9y23jj5Aw88kKxjeC+++GKyvmbNmtxavWsj6qn3+9SOOLIDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBBhxtlXrFiRrKfG0et5/PHHk/UlS5Yk66PZSy+9lFt75ZVXktumxskl6aOPPkrWT5w4kaynXHHFFcl66t/VrjiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQYcbZt2/fnqybWbI+derU3NqVV17ZUE+t8OSTTybrn376abL+8ssvJ+uvv/56sv7FF1/k1k6ePJnctpkuv/zyZL3eOHrq96Fd1T2ym9laMztqZvuHLHvYzP5sZnuzn/Qk4AAqN5K38eskXT/M8l+6+6zsZ2u5bQEoW92wu/urkj5sQS8AmqjICbp7zWxf9jZ/St5KZrbUzHrMrKdWqxXYHYAiGg37aknfljRLUr+kX+St6O7d7t7l7l31JjgE0DwNhd3dj7j7KXf/UtKvJDGNKNDmGgq7mXUOefgDSfvz1gXQHuqOs5vZRknXSJpmZocl/VzSNWY2S5JL6pP0k+a1WI6HHnooWa83X3fqe8brjdmezdw9Wa93fUKVxo4dm1tbtmxZctuzcRy9nrphd/fFwyxOf6sAgLbD5bJAEIQdCIKwA0EQdiAIwg4EEeYjrsuXL0/W9+zZk6xv3dq+n/WZMGFCbm3y5MmFnjs1fCXVH8IaGBjIrT3zzDPJbXt7e5P18ePHJ+urV6/Ord16663JbUcjjuxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EESYcfZx48Yl688++2yyvmnTpjLbKdUll1ySW7v66qubuu/UOLokPfroo7m1euPo9dx8883JeuSpsofDkR0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgggzzl5P6jPhknT77be3ppGzzP796SkDVqxY0fBzz5w5M1l/4oknGn7uiDiyA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQjLMj6dSpU8l66vPqRd19993J+rRp05q279Go7pHdzKab2e/NrNfM3jazn2bLp5rZDjM7kN1OaX67ABo1krfxA5KWuftMSd+VdI+ZXSbpQUk73f1SSTuzxwDaVN2wu3u/u7+Z3f9EUq+kiyQtkrQ+W229pBub1COAEpzRCTozmyHpO5L+IOlCd++XBv9DkHRBzjZLzazHzHpqtVrBdgE0asRhN7NJkjZL+pm7/2Wk27l7t7t3uXtXR0dHIz0CKMGIwm5mYzUY9N+4+++yxUfMrDOrd0o62pwWAZSh7tCbmZmkNZJ63X3oZwq3SFoi6bHs9oWmdIhKdXd3J+ubN29uUScoaiTj7HMl/VjSW2a2N1u2XIMh32Rmd0o6JOmHTekQQCnqht3dd0mynPL3ym0HQLNwuSwQBGEHgiDsQBCEHQiCsANB8BHX4OpNm7xy5coWdfJ1kyZNqmzfoxFHdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgnH24ObPn5+sHzlyJFkf/LqDfOedd15ubcOGDcltr7vuumQdZ4YjOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EwTh7cBdffHGyfujQoULPv3DhwtzaDTfcUOi5cWY4sgNBEHYgCMIOBEHYgSAIOxAEYQeCIOxAECOZn326pF9L+gdJX0rqdvdVZvawpH+VVMtWXe7uW5vVKJpj27ZtyfrJkycLPf+4ceMKbY/yjOSimgFJy9z9TTP7hqQ9ZrYjq/3S3f+jee0BKMtI5mfvl9Sf3f/EzHolXdTsxgCU64z+ZjezGZK+I+kP2aJ7zWyfma01syk52yw1sx4z66nVasOtAqAFRhx2M5skabOkn7n7XyStlvRtSbM0eOT/xXDbuXu3u3e5e1dHR0fxjgE0ZERhN7OxGgz6b9z9d5Lk7kfc/ZS7fynpV5LmNK9NAEXVDbsNfn3oGkm97v7EkOWdQ1b7gaT95bcHoCwjORs/V9KPJb1lZnuzZcslLTazWZJcUp+knzShPzRZvaExhs5Gj5Gcjd8labgvB2dMHTiLcAUdEARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCHP31u3MrCbpj0MWTZN0rGUNnJl27a1d+5LorVFl9vaP7j7s97+1NOxf27lZj7t3VdZAQrv21q59SfTWqFb1xtt4IAjCDgRRddi7K95/Srv21q59SfTWqJb0Vunf7ABap+ojO4AWIexAEJWE3cyuN7P/M7ODZvZgFT3kMbM+M3vLzPaaWU/Fvaw1s6Nmtn/IsqlmtsPMDmS3w86xV1FvD5vZn7PXbq+ZLaiot+lm9nsz6zWzt83sp9nySl+7RF8ted1a/je7mY2R9I6kf5Z0WNIbkha7+/+2tJEcZtYnqcvdK78Aw8zmSTou6dfu/k/Zsn+X9KG7P5b9RznF3R9ok94elnS86mm8s9mKOodOMy7pRkm3q8LXLtHXv6gFr1sVR/Y5kg66+7vufkLSbyUtqqCPtufur0r68LTFiyStz+6v1+AvS8vl9NYW3L3f3d/M7n8i6atpxit97RJ9tUQVYb9I0p+GPD6s9prv3SVtN7M9Zra06maGcaG790uDvzySLqi4n9PVnca7lU6bZrxtXrtGpj8vqoqwDzeVVDuN/81199mS5ku6J3u7ipEZ0TTerTLMNONtodHpz4uqIuyHJU0f8vibkt6roI9huft72e1RSc+r/aaiPvLVDLrZ7dGK+/mbdprGe7hpxtUGr12V059XEfY3JF1qZt8ys3GSfiRpSwV9fI2ZTcxOnMjMJkr6vtpvKuotkpZk95dIeqHCXv5Ou0zjnTfNuCp+7Sqf/tzdW/4jaYEGz8j/v6R/q6KHnL4ulvQ/2c/bVfcmaaMG39ad1OA7ojslnS9pp6QD2e3UNuptg6S3JO3TYLA6K+rtag3+abhP0t7sZ0HVr12ir5a8blwuCwTBFXRAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMRfAfh+NyZQ6us4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n"
     ]
    }
   ],
   "source": [
    "#let's try the plotting function\n",
    "plot_digit(X_train,y_train,100)\n",
    "plot_digit(X_test,y_test,40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Run SVM with 5-fold cross validation to pick the best kernel and values of parameters. We provide some potential choice for parameters, but change the grid if needed (e.g., it takes too long). For the SVM for classification use SVC from sklearn.svm; for the grid search we suggest you use GridSearchCV from sklearn.model_selection, but you can implement your own cross-validation for model selection if you prefer.\n",
    "\n",
    "Finally, print the best parameters used as well as the score obtained by the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRESULTS FOR LINEAR KERNEL\n",
      "\u001b[0m\n",
      "Best parameters set found: {'C': 1}\n",
      "Score with best parameters: 0.876\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091680</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>0.017591</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.088855</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097847</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.017499</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.091680      0.003899         0.017591        0.002045       1   \n",
       "1       0.088855      0.002267         0.017880        0.002581      10   \n",
       "2       0.097847      0.007674         0.017499        0.002992     100   \n",
       "\n",
       "       params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0    {'C': 1}               0.88               0.86               0.87   \n",
       "1   {'C': 10}               0.88               0.86               0.87   \n",
       "2  {'C': 100}               0.88               0.86               0.87   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0               0.86               0.91            0.876        0.018547   \n",
       "1               0.86               0.91            0.876        0.018547   \n",
       "2               0.86               0.91            0.876        0.018547   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mRESULTS FOR POLY DEGREE=2 KERNEL\n",
      "\u001b[0m\n",
      "Best parameters set found: {'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters: 0.8960000000000001\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075011</td>\n",
       "      <td>0.007540</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073550</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075397</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>0.015544</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1, 'gamma': 1.0}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119725</td>\n",
       "      <td>0.021623</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.132317</td>\n",
       "      <td>0.021926</td>\n",
       "      <td>0.029438</td>\n",
       "      <td>0.006231</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.136571</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.023257</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 10, 'gamma': 1.0}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.129129</td>\n",
       "      <td>0.026967</td>\n",
       "      <td>0.018974</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.124581</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.020337</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.102864</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.017854</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 100, 'gamma': 1.0}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.075011      0.007540         0.015790        0.001501       1   \n",
       "1       0.073550      0.002104         0.011962        0.001393       1   \n",
       "2       0.075397      0.005468         0.015544        0.001653       1   \n",
       "3       0.119725      0.021623         0.025889        0.010342      10   \n",
       "4       0.132317      0.021926         0.029438        0.006231      10   \n",
       "5       0.136571      0.003766         0.023257        0.004790      10   \n",
       "6       0.129129      0.026967         0.018974        0.004184     100   \n",
       "7       0.124581      0.004381         0.020337        0.003432     100   \n",
       "8       0.102864      0.004849         0.017854        0.001331     100   \n",
       "\n",
       "  param_gamma                     params  split0_test_score  \\\n",
       "0        0.01    {'C': 1, 'gamma': 0.01}               0.82   \n",
       "1         0.1     {'C': 1, 'gamma': 0.1}               0.87   \n",
       "2         1.0     {'C': 1, 'gamma': 1.0}               0.87   \n",
       "3        0.01   {'C': 10, 'gamma': 0.01}               0.87   \n",
       "4         0.1    {'C': 10, 'gamma': 0.1}               0.87   \n",
       "5         1.0    {'C': 10, 'gamma': 1.0}               0.87   \n",
       "6        0.01  {'C': 100, 'gamma': 0.01}               0.87   \n",
       "7         0.1   {'C': 100, 'gamma': 0.1}               0.87   \n",
       "8         1.0   {'C': 100, 'gamma': 1.0}               0.87   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0               0.84               0.84               0.86               0.87   \n",
       "1               0.89               0.90               0.90               0.91   \n",
       "2               0.89               0.90               0.90               0.91   \n",
       "3               0.91               0.90               0.90               0.90   \n",
       "4               0.89               0.90               0.90               0.91   \n",
       "5               0.89               0.90               0.90               0.91   \n",
       "6               0.89               0.90               0.90               0.91   \n",
       "7               0.89               0.90               0.90               0.91   \n",
       "8               0.89               0.90               0.90               0.91   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.846        0.017436                9  \n",
       "1            0.894        0.013565                2  \n",
       "2            0.894        0.013565                2  \n",
       "3            0.896        0.013565                1  \n",
       "4            0.894        0.013565                2  \n",
       "5            0.894        0.013565                2  \n",
       "6            0.894        0.013565                2  \n",
       "7            0.894        0.013565                2  \n",
       "8            0.894        0.013565                2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mRESULTS FOR rbf KERNEL\n",
      "\u001b[0m\n",
      "Best parameters set found: {'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters: 0.9040000000000001\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078957</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.025772</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.149932</td>\n",
       "      <td>0.018904</td>\n",
       "      <td>0.045539</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.016733</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>0.070957</td>\n",
       "      <td>0.015498</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1, 'gamma': 1.0}</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.168904</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>0.047238</td>\n",
       "      <td>0.004319</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.231344</td>\n",
       "      <td>0.024639</td>\n",
       "      <td>0.052333</td>\n",
       "      <td>0.004728</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.212146</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.053026</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 10, 'gamma': 1.0}</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.160258</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.217422</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.051495</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.016248</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.203879</td>\n",
       "      <td>0.017841</td>\n",
       "      <td>0.036290</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 100, 'gamma': 1.0}</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.078957      0.006563         0.025772        0.000567       1   \n",
       "1       0.149932      0.018904         0.045539        0.011896       1   \n",
       "2       0.209467      0.023363         0.070957        0.015498       1   \n",
       "3       0.168904      0.021263         0.047238        0.004319      10   \n",
       "4       0.231344      0.024639         0.052333        0.004728      10   \n",
       "5       0.212146      0.003735         0.053026        0.002810      10   \n",
       "6       0.160258      0.002929         0.043038        0.003699     100   \n",
       "7       0.217422      0.010966         0.051495        0.002389     100   \n",
       "8       0.203879      0.017841         0.036290        0.009394     100   \n",
       "\n",
       "  param_gamma                     params  split0_test_score  \\\n",
       "0        0.01    {'C': 1, 'gamma': 0.01}               0.87   \n",
       "1         0.1     {'C': 1, 'gamma': 0.1}               0.38   \n",
       "2         1.0     {'C': 1, 'gamma': 1.0}               0.14   \n",
       "3        0.01   {'C': 10, 'gamma': 0.01}               0.89   \n",
       "4         0.1    {'C': 10, 'gamma': 0.1}               0.44   \n",
       "5         1.0    {'C': 10, 'gamma': 1.0}               0.14   \n",
       "6        0.01  {'C': 100, 'gamma': 0.01}               0.89   \n",
       "7         0.1   {'C': 100, 'gamma': 0.1}               0.44   \n",
       "8         1.0   {'C': 100, 'gamma': 1.0}               0.14   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0               0.91               0.90               0.89               0.91   \n",
       "1               0.37               0.38               0.41               0.36   \n",
       "2               0.14               0.14               0.15               0.15   \n",
       "3               0.91               0.90               0.91               0.91   \n",
       "4               0.46               0.44               0.43               0.41   \n",
       "5               0.14               0.14               0.15               0.15   \n",
       "6               0.91               0.90               0.91               0.91   \n",
       "7               0.46               0.44               0.43               0.41   \n",
       "8               0.14               0.14               0.15               0.15   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.896        0.014967                3  \n",
       "1            0.380        0.016733                6  \n",
       "2            0.144        0.004899                7  \n",
       "3            0.904        0.008000                1  \n",
       "4            0.436        0.016248                4  \n",
       "5            0.144        0.004899                7  \n",
       "6            0.904        0.008000                1  \n",
       "7            0.436        0.016248                4  \n",
       "8            0.144        0.004899                7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [1, 10, 100]}\n",
    "\n",
    "#run linear SVM\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "\n",
    "#find best model using 5-fold CV \n",
    "#and train it using all the training data\n",
    "clf = GridSearchCV(estimator=linear_SVM, param_grid=parameters, cv=5,n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print ('\\033[1m'+'RESULTS FOR LINEAR KERNEL\\n'+'\\033[0m')\n",
    "\n",
    "print(\"Best parameters set found:\", clf.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\", clf.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "display(pd.DataFrame(clf.cv_results_))\n",
    "\n",
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "poly2_SVM = SVC(kernel='poly',degree=2)\n",
    "\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR POLYNOMIAL KERNEL WITH DEGREE=2\n",
    "#find best model using 5-fold CV \n",
    "#and train it using all the training data\n",
    "clf_poly2 = GridSearchCV(estimator=poly2_SVM, param_grid=parameters, cv=5,n_jobs=-1)\n",
    "clf_poly2.fit(X_train,y_train)\n",
    "\n",
    "print ('\\n'+'\\033[1m'+'RESULTS FOR POLY DEGREE=2 KERNEL\\n'+'\\033[0m')\n",
    "\n",
    "print(\"Best parameters set found:\", clf_poly2.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\", clf_poly2.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "display(pd.DataFrame(clf_poly2.cv_results_))\n",
    "\n",
    "# parameters for rbf SVM\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "rbf_SVM = SVC(kernel='rbf')\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR RBF KERNEL\n",
    "#find best model using 5-fold CV \n",
    "#and train it using all the training data\n",
    "clf_rbf = GridSearchCV(estimator=rbf_SVM, param_grid=parameters, cv=5,n_jobs=-1)\n",
    "clf_rbf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print ('\\n'+'\\033[1m'+'RESULTS FOR rbf KERNEL\\n'+'\\033[0m')\n",
    "\n",
    "print(\"Best parameters set found:\",clf_rbf.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\", clf_rbf.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "display(pd.DataFrame(clf_rbf.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "For the \"best\" SVM kernel and choice of parameters from above, train the model on the entire training set and measure the training error. Also make predictions on the test set and measure the test error. Print the training and the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.107165\n"
     ]
    }
   ],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = clf_rbf.best_estimator_\n",
    "\n",
    "# fit the model on the entire training set\n",
    "# ADD CODE\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "#get the training and test error\n",
    "training_error = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use logistic regression for comparison\n",
    "\n",
    "## TO DO 3\n",
    "\n",
    "Just for comparison let's also use logistic regression, first with the default values of the parameter for regularization and then with cross-validation to fix the value of the parameters. For cross validation, use 5-fold cross validation and the default values of the regularization parameters for the function linear_model.LogisticRegressionCV(...).\n",
    "\n",
    "Note: during training you may receive a \"ConvergenceWarning\" that indicates that the logistic regression solver did not converge to the optimal result. Given the scope of the notebook, we can ignore such warning but in real-world scenarios you should take corrective measures such as increasing the number of training iterations and/or the runtime for training or picking a different optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.156547\n",
      "Best logistic regression training error with CV: 0.000000\n",
      "Best logistic regression test error with CV: 0.156086\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr = linear_model.LogisticRegression(max_iter=1000)\n",
    "# fit the model on the training data\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#compute training and test error for model above\n",
    "training_error_lr = 1. - lr.score(X_train,y_train)\n",
    "test_error_lr = 1. - lr.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error_lr)\n",
    "print (\"Best logistic regression test error: %f\" % test_error_lr)\n",
    "\n",
    "#logistic regression with 5-fold CV: you can use use linear_model.LogisticRegressionCV\n",
    "# use 5-fold CV to find the best choice of the parameter, than train\n",
    "# the model on the entire training set\n",
    "lr_cv = LogisticRegressionCV(cv=5,max_iter=1000).fit(X_train, y_train)\n",
    "training_error_cv = 1. - lr_cv.score(X_train, y_train)\n",
    "test_error_cv = 1. - lr_cv.score(X_test, y_test)\n",
    "\n",
    "print (\"Best logistic regression training error with CV: %f\" % training_error_cv)\n",
    "print (\"Best logistic regression test error with CV: %f\" % test_error_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO 4 \n",
    "Compare and comment the results from SVM and logistic regression.\n",
    "\n",
    "#### Comment:\n",
    "As we can see by the table below, the SVM performs $\\sim 5\\%$ better than a logistic regression model, with or without CV. This is because SVM works best with unstructured or semi-structured data like text or images while logistic regression performs best with independent variables.\n",
    "SVM works best with RBF kernel, since rbf is a non-linear kernel this means that the data is not linearly separable.\n",
    "Of course, Logistic Regression with Cross Validation performs better than the model without it since we apply GridSearchCV to find the best hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     SVM        LR    LR with CV\n",
      "--------------  --------  --------  ------------\n",
      "Training error         0         0             0\n",
      "Test error      0.107165  0.156547      0.156086\n"
     ]
    }
   ],
   "source": [
    "# print table\n",
    "\n",
    "table = [[\"Training error\", training_error, training_error_lr, training_error_cv], [\"Test error\", test_error, test_error_lr, test_error_cv]]\n",
    "print(tabulate(table,headers=[\"SVM\",\"LR\", \"LR with CV\"],numalign=\"right\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TO DO 5\n",
    "Write the code that finds and plots a digit that is missclassified by logistic regression (optimized for the regularization parameter) and correctly classified by the \"best\" SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassified points by linear regression but correctly classified by SVM:  4171\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n"
     ]
    }
   ],
   "source": [
    "y_test_np = np.asarray(y_test)\n",
    "misclassified_lr = np.where(y_test_np != lr_cv.predict(X_test))\n",
    "classified_svm = np.where(y_test_np == clf_rbf.predict(X_test))\n",
    "print(\"Missclassified points by linear regression but correctly classified by SVM: \", len(np.intersect1d(misclassified_lr, classified_svm)))\n",
    "plot_digit(X_train,y_train,np.intersect1d(misclassified_lr, classified_svm)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using 1000 data points for training. \n",
    "\n",
    "## TO DO 6\n",
    "Repeat the entire analysis above using 1000 samples. Of course you can copy the code from above (but no need to copy markdown comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRESULTS FOR LINEAR KERNEL\n",
      "\u001b[0m\n",
      "Best parameters set found: {'C': 1}\n",
      "Score with best parameters: 0.8460000000000001\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288912</td>\n",
       "      <td>0.062724</td>\n",
       "      <td>0.133407</td>\n",
       "      <td>0.031209</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.027276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.378605</td>\n",
       "      <td>0.052470</td>\n",
       "      <td>0.084252</td>\n",
       "      <td>0.009069</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.027276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.350452</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.067754</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.027276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.288912      0.062724         0.133407        0.031209       1   \n",
       "1       0.378605      0.052470         0.084252        0.009069      10   \n",
       "2       0.350452      0.005502         0.067754        0.011589     100   \n",
       "\n",
       "       params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0    {'C': 1}               0.86               0.83               0.87   \n",
       "1   {'C': 10}               0.86               0.83               0.87   \n",
       "2  {'C': 100}               0.86               0.83               0.87   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0                0.8               0.87            0.846        0.027276   \n",
       "1                0.8               0.87            0.846        0.027276   \n",
       "2                0.8               0.87            0.846        0.027276   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                1  \n",
       "2                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mRESULTS FOR POLY DEGREE=2 KERNEL\n",
      "\u001b[0m\n",
      "Best parameters set found: {'C': 1, 'gamma': 0.1}\n",
      "Score with best parameters: 0.8779999999999999\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.457309</td>\n",
       "      <td>0.048628</td>\n",
       "      <td>0.107858</td>\n",
       "      <td>0.019701</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.043589</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.420580</td>\n",
       "      <td>0.058675</td>\n",
       "      <td>0.094279</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.483136</td>\n",
       "      <td>0.032593</td>\n",
       "      <td>0.091937</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1, 'gamma': 1.0}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.487627</td>\n",
       "      <td>0.063422</td>\n",
       "      <td>0.087865</td>\n",
       "      <td>0.016868</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.474803</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.473329</td>\n",
       "      <td>0.029257</td>\n",
       "      <td>0.087723</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 10, 'gamma': 1.0}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.472393</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>0.102978</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.476089</td>\n",
       "      <td>0.035041</td>\n",
       "      <td>0.092248</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.349984</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.056268</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 100, 'gamma': 1.0}</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.033705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.457309      0.048628         0.107858        0.019701       1   \n",
       "1       0.420580      0.058675         0.094279        0.006044       1   \n",
       "2       0.483136      0.032593         0.091937        0.007722       1   \n",
       "3       0.487627      0.063422         0.087865        0.016868      10   \n",
       "4       0.474803      0.015518         0.087962        0.011200      10   \n",
       "5       0.473329      0.029257         0.087723        0.004801      10   \n",
       "6       0.472393      0.022918         0.102978        0.008275     100   \n",
       "7       0.476089      0.035041         0.092248        0.003415     100   \n",
       "8       0.349984      0.018331         0.056268        0.007802     100   \n",
       "\n",
       "  param_gamma                     params  split0_test_score  \\\n",
       "0        0.01    {'C': 1, 'gamma': 0.01}              0.900   \n",
       "1         0.1     {'C': 1, 'gamma': 0.1}              0.895   \n",
       "2         1.0     {'C': 1, 'gamma': 1.0}              0.895   \n",
       "3        0.01   {'C': 10, 'gamma': 0.01}              0.895   \n",
       "4         0.1    {'C': 10, 'gamma': 0.1}              0.895   \n",
       "5         1.0    {'C': 10, 'gamma': 1.0}              0.895   \n",
       "6        0.01  {'C': 100, 'gamma': 0.01}              0.895   \n",
       "7         0.1   {'C': 100, 'gamma': 0.1}              0.895   \n",
       "8         1.0   {'C': 100, 'gamma': 1.0}              0.895   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0              0.785              0.865              0.845              0.905   \n",
       "1              0.835              0.905              0.840              0.915   \n",
       "2              0.835              0.905              0.840              0.915   \n",
       "3              0.835              0.900              0.845              0.915   \n",
       "4              0.835              0.905              0.840              0.915   \n",
       "5              0.835              0.905              0.840              0.915   \n",
       "6              0.835              0.905              0.840              0.915   \n",
       "7              0.835              0.905              0.840              0.915   \n",
       "8              0.835              0.905              0.840              0.915   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.860        0.043589                9  \n",
       "1            0.878        0.033705                1  \n",
       "2            0.878        0.033705                1  \n",
       "3            0.878        0.031875                1  \n",
       "4            0.878        0.033705                1  \n",
       "5            0.878        0.033705                1  \n",
       "6            0.878        0.033705                1  \n",
       "7            0.878        0.033705                1  \n",
       "8            0.878        0.033705                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mRESULTS FOR rbf KERNEL\n",
      "\u001b[0m\n",
      "Best parameters set found: {'C': 10, 'gamma': 0.01}\n",
      "Score with best parameters: 0.9020000000000001\n",
      "\n",
      "All scores on the grid:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.416375</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.231627</td>\n",
       "      <td>0.011120</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.035553</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.155925</td>\n",
       "      <td>0.035563</td>\n",
       "      <td>0.244545</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 1, 'gamma': 0.1}</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.028178</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.216201</td>\n",
       "      <td>0.027241</td>\n",
       "      <td>0.251188</td>\n",
       "      <td>0.013747</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 1, 'gamma': 1.0}</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.577588</td>\n",
       "      <td>0.018093</td>\n",
       "      <td>0.197686</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.259989</td>\n",
       "      <td>0.063860</td>\n",
       "      <td>0.253479</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.271393</td>\n",
       "      <td>0.049208</td>\n",
       "      <td>0.266691</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 10, 'gamma': 1.0}</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.606170</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.219921</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.033556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.249426</td>\n",
       "      <td>0.018898</td>\n",
       "      <td>0.252857</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 100, 'gamma': 0.1}</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.069546</td>\n",
       "      <td>0.306426</td>\n",
       "      <td>0.164023</td>\n",
       "      <td>0.062962</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'C': 100, 'gamma': 1.0}</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.416375      0.021266         0.231627        0.011120       1   \n",
       "1       1.155925      0.035563         0.244545        0.009340       1   \n",
       "2       1.216201      0.027241         0.251188        0.013747       1   \n",
       "3       0.577588      0.018093         0.197686        0.007895      10   \n",
       "4       1.259989      0.063860         0.253479        0.022691      10   \n",
       "5       1.271393      0.049208         0.266691        0.013483      10   \n",
       "6       0.606170      0.020202         0.219921        0.005828     100   \n",
       "7       1.249426      0.018898         0.252857        0.016397     100   \n",
       "8       1.069546      0.306426         0.164023        0.062962     100   \n",
       "\n",
       "  param_gamma                     params  split0_test_score  \\\n",
       "0        0.01    {'C': 1, 'gamma': 0.01}              0.910   \n",
       "1         0.1     {'C': 1, 'gamma': 0.1}              0.480   \n",
       "2         1.0     {'C': 1, 'gamma': 1.0}              0.125   \n",
       "3        0.01   {'C': 10, 'gamma': 0.01}              0.905   \n",
       "4         0.1    {'C': 10, 'gamma': 0.1}              0.530   \n",
       "5         1.0    {'C': 10, 'gamma': 1.0}              0.135   \n",
       "6        0.01  {'C': 100, 'gamma': 0.01}              0.905   \n",
       "7         0.1   {'C': 100, 'gamma': 0.1}              0.530   \n",
       "8         1.0   {'C': 100, 'gamma': 1.0}              0.135   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0              0.850              0.905              0.850              0.940   \n",
       "1              0.460              0.410              0.435              0.485   \n",
       "2              0.125              0.125              0.125              0.125   \n",
       "3              0.860              0.925              0.870              0.950   \n",
       "4              0.505              0.485              0.510              0.540   \n",
       "5              0.125              0.135              0.135              0.130   \n",
       "6              0.860              0.925              0.870              0.950   \n",
       "7              0.505              0.485              0.510              0.540   \n",
       "8              0.125              0.135              0.135              0.130   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.891        0.035553                3  \n",
       "1            0.454        0.028178                6  \n",
       "2            0.125        0.000000                9  \n",
       "3            0.902        0.033556                1  \n",
       "4            0.514        0.019339                4  \n",
       "5            0.132        0.004000                7  \n",
       "6            0.902        0.033556                1  \n",
       "7            0.514        0.019339                4  \n",
       "8            0.132        0.004000                7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM training error: 0.000000\n",
      "Best SVM test error: 0.107165\n"
     ]
    }
   ],
   "source": [
    "#random permute the data and split into training and test taking the first 500\n",
    "#data samples as training and the rests as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 1000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [1, 10, 100]}\n",
    "\n",
    "#run linear SVM\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "\n",
    "#find best model using 5-fold CV \n",
    "#and train it using all the training data\n",
    "clf = GridSearchCV(estimator=linear_SVM, param_grid=parameters, cv=5,n_jobs=-1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print ('\\033[1m'+'RESULTS FOR LINEAR KERNEL\\n'+'\\033[0m')\n",
    "\n",
    "print(\"Best parameters set found:\", clf.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\", clf.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "display(pd.DataFrame(clf.cv_results_))\n",
    "\n",
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "poly2_SVM = SVC(kernel='poly',degree=2)\n",
    "\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR POLYNOMIAL KERNEL WITH DEGREE=2\n",
    "#find best model using 5-fold CV \n",
    "#and train it using all the training data\n",
    "clf_poly2 = GridSearchCV(estimator=poly2_SVM, param_grid=parameters, cv=5,n_jobs=-1)\n",
    "clf_poly2.fit(X_train,y_train)\n",
    "\n",
    "print ('\\n'+'\\033[1m'+'RESULTS FOR POLY DEGREE=2 KERNEL\\n'+'\\033[0m')\n",
    "\n",
    "print(\"Best parameters set found:\", clf_poly2.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\", clf_poly2.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "display(pd.DataFrame(clf_poly2.cv_results_))\n",
    "\n",
    "# parameters for rbf SVM\n",
    "parameters = {'C': [1, 10, 100],'gamma':[0.01,0.1,1.]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "rbf_SVM = SVC(kernel='rbf')\n",
    "# ADD CODE: DO THE SAME AS ABOVE FOR RBF KERNEL\n",
    "#find best model using 5-fold CV \n",
    "#and train it using all the training data\n",
    "clf_rbf = GridSearchCV(estimator=rbf_SVM, param_grid=parameters, cv=5,n_jobs=-1)\n",
    "clf_rbf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print ('\\n'+'\\033[1m'+'RESULTS FOR rbf KERNEL\\n'+'\\033[0m')\n",
    "\n",
    "print(\"Best parameters set found:\",clf_rbf.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\", clf_rbf.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\")\n",
    "display(pd.DataFrame(clf_rbf.cv_results_))\n",
    "\n",
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = clf_rbf.best_estimator_\n",
    "\n",
    "# fit the model on the entire training set\n",
    "# ADD CODE\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "#get the training and test error\n",
    "training_error_1000 = 1. - best_SVM.score(X_train,y_train)\n",
    "test_error_1000 = 1. - best_SVM.score(X_test,y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression training error: 0.000000\n",
      "Best logistic regression test error: 0.107165\n",
      "Best logistic regression training error with CV: 0.000000\n",
      "Best logistic regression test error with CV: 0.156086\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "lr = linear_model.LogisticRegression(max_iter=1000)\n",
    "# fit the model on the training data\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "#compute training and test error for model above\n",
    "training_error_lr_1000 = 1. - lr.score(X_train,y_train)\n",
    "test_error_lr_1000 = 1. - lr.score(X_test,y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)\n",
    "\n",
    "#logistic regression with 5-fold CV: you can use use linear_model.LogisticRegressionCV\n",
    "# use 5-fold CV to find the best choice of the parameter, than train\n",
    "# the model on the entire training set\n",
    "lr_cv = LogisticRegressionCV(cv=5,max_iter=1000).fit(X_train, y_train)\n",
    "training_error_cv_1000 = 1. - lr_cv.score(X_train, y_train)\n",
    "test_error_cv_1000 = 1. - lr_cv.score(X_test, y_test)\n",
    "\n",
    "print (\"Best logistic regression training error with CV: %f\" % training_error_cv)\n",
    "print (\"Best logistic regression test error with CV: %f\" % test_error_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missclassified points by linear regression but correctly classified by SVM:  4189\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 4\n"
     ]
    }
   ],
   "source": [
    "y_test_np = np.asarray(y_test)\n",
    "misclassified_lr = np.where(y_test_np != lr_cv.predict(X_test))\n",
    "classified_svm = np.where(y_test_np == clf_rbf.predict(X_test))\n",
    "print(\"Missclassified points by linear regression but correctly classified by SVM: \", len(np.intersect1d(misclassified_lr, classified_svm)))\n",
    "plot_digit(X_train,y_train,np.intersect1d(misclassified_lr, classified_svm)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 7\n",
    "Compare and comment on the differences with the results above.\n",
    "\n",
    "#### Comment:\n",
    "As we could expect, all models with 1000 points for the training set perform much better than the models with 500 points, since enlarging the training set with more relevant training data (almost) always improves the model. Still, SVM performs better than LR with or without CV.\n",
    "The SVM gets the smaller improvement out of the 3, but still performs $\\sim1.6$x better than the best logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       SVM        LR    LR with CV\n",
      "---------------  ---------  --------  ------------\n",
      "test error 500    0.107165  0.156547      0.156086\n",
      "test error 1000  0.0825217  0.137174      0.132478\n",
      "\n",
      "Improvements: 0.02464372849546448 0.0193728495464498 0.02360807006568655\n"
     ]
    }
   ],
   "source": [
    "table = [[\"test error 500\", test_error, test_error_lr, test_error_cv], [\"test error 1000\", test_error_1000, test_error_lr_1000, test_error_cv_1000]]\n",
    "print(tabulate(table,headers=[\"SVM\",\"LR\", \"LR with CV\"],numalign=\"right\"))\n",
    "\n",
    "print(\"\\nImprovements:\",test_error-test_error_1000,test_error_lr-test_error_lr_1000,test_error_cv-test_error_cv_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
